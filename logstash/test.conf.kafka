input {
  kafka {
    zk_connect => 'localhost:2181'
    group_id => 'logstash'
    topic_id => 'testing'
    consumer_restart_on_error => true
    consumer_restart_sleep_ms => 100
    consumer_id => "mylocohst"
    codec => 'json'
  }
}

filter {
  date {
    match => ["timestamp", 
      "yyyyMMddHHmmss", 
      "yyyy-MM-dd HH:mm:ss",
      "MMM dd HH:mm:ss.SSS",
      "MMM d HH:mm:ss.SSS",
      "MMM dd HH:mm:ss",
      "MMM d HH:mm:ss",
      "MMM dd yyyy HH:mm:ss.SSS",
      "MMM d yyyy HH:mm:ss.SSS",
      "MMM dd yyyy HH:mm:ss",
      "MMM d yyyy HH:mm:ss" ]
    add_tag => ["dated"]  
  }

  uuid { 
    target => "@uuid"
  }
}

output {
  stdout {
     codec => rubydebug
  }

  elasticsearch {
    protocol => "transport"
    host => "127.0.0.1"
    port => "9300"
    cluster => "iShark" 
    index => "%{test}-%{+YYYY.MM.dd}"
    workers => 2
  }
}
