input {
  # file {
	# 	add_field => ["system", "mytest"]
  #   start_position => beginning
  #   path => ["/var/log/syslog", "/var/log/auth.log", "/var/log/kern.log", "/home/bigbox/github/tianfu/logstash-1.4.0/logs/catalina.out.1"]
	# 	# codec => plain {
	# 	# 			charset => "GB2312"
	# 	# 			}
  # }

  file {
		add_field => ["system", "nsag"]
    start_position => beginning
    path => ["/media/user/Windows7_OS/tianfu/logs/data/nsag/temp1/*.r"]
  }

  file {
		add_field => ["system", "wap"]
    start_position => beginning
    path => ["/media/user/Windows7_OS/tianfu/logs/access.log.20140320_4"]
  }

  file {
		add_field => ["system", "network"]
    start_position => beginning
    path => ["/media/user/Windows7_OS/tianfu/logs/syslog1/cisco.log"]
  }

}

filter {
  if [path] =~ "auth.log|kern.log" {
		 mutate { replace => { type => "syslog" } }

		 grok {
		 			break_on_match => true
      		match => { 
								"message" => ["%{CRONLOG}", "%{SYSLOGLINE}",
														 "%{SYSLOGTIMESTAMP} %{GREEDYDATA:msg}" ]
								}
					add_field => [ "received_at", "%{@timestamp}" ]
					# overwrite => [ "message" ]
    }
  } 
  else if [path] =~ "catalina.out" {
			 mutate { replace => { type => "tomcat" } }

   		 multiline {
       					 patterns_dir => "/home/bigbox/github/tianfu/logstash-1.4.0/patterns/my-patterns"
								 stream_identity => "%{host}.%{path}.%{type}"
      					 # pattern => "(^%{TOMCAT_DATESTAMP})|(^%{CATALINA_DATESTAMP})|(^%{TIMESTAMP_ISO8601})"
      					 # negate => true
								 
								 # copy from http://www.logstashbook.com/code/6/shipper.conf
								 pattern => "(^\d+\serror)|(^.+Exception: .+)|(^\s+at .+)|(^\s+... \d+ more)|(^\s*Caused by:.+)"
								 # pattern => "(^\s)"
								 negate => false
      					 what => "previous"
			}


			grok {
 		 			 	match => { 
									# "[APKP]-2014-05-13 09:00:15,050[INFO][crb.controller.TSMServer]-
									"message" => ["\[%{WORD:module}\]-%{TIMESTAMP_ISO8601:timestamp}\[%{LOGLEVEL:loglevel}\]\[%{JAVACLASS:javaclass}\]-%{GREEDYDATA:msg}"]
		 			 }
					 # overwrite => [ "message" ]
					 add_field => ["received_at", "%{@timestamp}"]
  		}
	}
  else if [path] =~ "\.r$" {
		# mutate { replace => { type => "nsag" } }
		if [path] =~ "L_100" {
			 mutate { replace => { type => "nsag-dx-ok" } }
		} else if [path] =~ "L_101" {
			mutate { replace => { type => "nsag-dx-error" } }
		} else if [path] =~ "L_102" {
			mutate { replace => { type => "nsag-cx-ok" } }
		} else if [path] =~ "L_103" {
			mutate { replace => { type => "nsag-cx-error" } }
		} else if [path] =~ "L_104" {
			mutate { replace => { type => "nsag-wappush-ok" } }
		} else if [path] =~ "L_105" {
			mutate { replace => { type => "nsag-wappush-error" } }
		}
			grok {
 		 			 	match => { 
									# 20140422173751|0|NotifySmsDeliveryReceipt||||35101367|135000000000000223474|35101367|0|1|19350101380421181749000866F|0|0|0||0||||0||0||18921176309|18921176309|0|0||||0|||0|5|235000000000000027787|18921176309|
									"message" => ["%{DATESTAMP1:timestamp}\|%{DATA}\|%{WORD:msg_type}\|%{DATA:code01}\|%{DATA:code02}\|%{DATA:code03}\|%{DATA:sp_code}\|%{DATA:business_code}\|(%{DATA}\|){20,30}%{DATA:phone_num}\|%{DATA}"]

		 			 }
					 # overwrite => [ "message" ]
					 add_field => ["received_at", "%{@timestamp}"]
  		}
	}			 				 
  else if [path] =~ "access.log" {
		mutate { replace => { type => "web-access-log" } }

			grok {
 		 			 	match => { 
									# 10.234.139.12|2014-03-20 00:00:00|"GET /02.gif HTTP/1.1"|304|-|1000|18979805988|"Mozilla/5.0 (YL-COOLPAD_E600/10.14.E600;U;REX/1.0;BREW/3.1.5SP01;240*320;CTC/2.0) POLARIS/V6.15.090923"|"http://wapvnet.ifeng.com/news/zhuanti/mainland/dmfbj/zx/news?vt=2&aid=80015363&mid=7redRy"
									"message" => ["%{IP:client_ip}\|%{TIMESTAMP_ISO8601:timestamp}\|%{GREEDYDATA:action}\|%{GREEDYDATA:code}\|%{GREEDYDATA}\|%{GREEDYDATA}\|%{GREEDYDATA:phone_num}\|%{GREEDYDATA:agent}\|%{GREEDYDATA:refer}"]
		 			 }
					 # overwrite => [ "message" ]
					 add_field => ["received_at", "%{@timestamp}"]
  		}

			if [client_ip] !~ "10\.*" {
				 geoip {
    				source => "client_ip"
						add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
      			add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}"  ]
  		   }
			}			
		
		 if [geoip] { 
		 		mutate {
      				 convert => [ "[geoip][coordinates]", "float" ]
    					 }
			}
	} else if [path] =~ "cisco.log" {
		mutate { replace => { type => "cisco-fw-log" } }
	 	 grok {
 			add_tag => "cisco-fw"
			# patterns_dir => "/etc/logstash/patterns"
			match => {
							 "message" => [
							 "%{SYSLOGTIMESTAMP:syslog_timestamp} %{IP:log_source}\s:%{SYSLOGTIMESTAMP1:@timestamp}:%{GREEDYDATA:message}"]
							 }
			overwrite => ["message"]
			}
# 		syslog_pri {
# 							 tags => "cisco-fw"
# 							 }
		# mutate {
		# 			 # tags => "cisco-fw"
		# 			 exclude_tags => "_grokparsefailure"
		# 			 replace => [ "@source_host", "%{log_source}" ]
		# 			 replace => [ "@message", "%{log_message}" ]
		# 			 }

# 		# for optional fields (device name in message, Cisco syslog tag)
		grok {
				 tags => "cisco-fw"
				 # patterns_dir => "/etc/logstash/patterns"
				 # pattern => "(?:%{SYSLOGHOST:device} )?(?:: )?%%{CISCOFWTAG:ciscotag}:%{GREEDYDATA}"

				 match => [
								"message", "%{CISCOFW106015}",
     		 			  "message", "%{CISCOFW106001}",
								"message", "%{CISCOFW106006_106007_106010}",
								"message", "%{CISCOFW106014}",
								"message", "%{CISCOFW106021}",
								"message", "%{CISCOFW106023}",
								"message", "%{CISCOFW106100}",
								"message", "%{CISCOFW110002}",
								"message", "%{CISCOFW302010}",
								"message", "%{CISCOFW302013_302014_302015_302016}",
								"message", "%{CISCOFW302020_302021}",
								"message", "%{CISCOFW305011}",
								"message", "%{CISCOFW313001_313004_313008}",
								"message", "%{CISCOFW313005}",
								"message", "%{CISCOFW402117}",
								"message", "%{CISCOFW402119}",
								"message", "%{CISCOFW419001}",
								"message", "%{CISCOFW419002}",
								"message", "%{CISCOFW500004}",
								"message", "%{CISCOFW602303_602304}",
								"message", "%{CISCOFW710001_710002_710003_710005_710006}",
								"message", "%{CISCOFW713172}",
								"message", "%{CISCOFW733100}"
								]
				 }
 
# # we extract fields
# 		 # grok {
# 		 # 			tags => "cisco-fw"
# 		 # 			break_on_match => false
# 		 # 			patterns_dir => "/etc/logstash/patterns"
# 		 # 			pattern => []
# 		 # 		}

  }
	date {
					match => ["timestamp", 
									 "yyyyMMddHHmmss", 
									 "yyyy-MM-dd HH:mm:ss",
									 "MMM dd HH:mm:ss.SSS",
									 "MMM d HH:mm:ss.SSS",
									 "MMM dd HH:mm:ss",
									 "MMM d HH:mm:ss",
									 "MMM dd yyyy HH:mm:ss.SSS",
									 "MMM d yyyy HH:mm:ss.SSS",
									 "MMM dd yyyy HH:mm:ss",
									 "MMM d yyyy HH:mm:ss"
									 ]
					add_tag => ["dated"]
					
	}

  uuid { 
    target => "@uuid"
		# remove_field =>  ["timestamp"]
  	}
}

output {
			 if ("_grokparsefailure" in [tags]) {
  		 		# stdout { 
    			# 			 codec => rubydebug }
					file { 
								 path => "errors.log"
								 codec => rubydebug
								 }
			}
			# stdout {
    	#  					 codec => rubydebug }

			# file { 
			# 		 path => "/tmp/tmp1.out"
			# 		 codec => rubydebug
			# }
			
			elasticsearch {
    								protocol => "transport"
    								host => "127.0.0.1"
    								port => "9300"
    								cluster => "iShark" 
										index => "%{system}-%{+YYYY.MM.dd}"
										workers => 2
										}
}
